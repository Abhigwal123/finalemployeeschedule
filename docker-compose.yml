# Docker Compose Configuration
# Note: 'version' is no longer required in Docker Compose v2+
services:
  # MySQL Database
  mysql:
    image: mysql:8.0
    container_name: scheduling-mysql
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD:-rootpassword}
      - MYSQL_DATABASE=${MYSQL_DATABASE:-scheduling_system}
      - MYSQL_USER=${MYSQL_USER:-scheduling_user}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD:-scheduling_password}
    volumes:
      - mysql_data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-uroot", "-p${MYSQL_ROOT_PASSWORD:-rootpassword}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - scheduling-network
    restart: unless-stopped
    command: --default-authentication-plugin=mysql_native_password --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci

  # Redis - Message broker and result backend for Celery
  redis:
    image: redis:7-alpine
    container_name: scheduling-redis
    ports:
      - "${REDIS_PORT:-6379}:6379"  # Use REDIS_PORT env var or default to 6379
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - scheduling-network
    restart: unless-stopped

  # Backend Flask Application
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: scheduling-backend
    ports:
      - "8081:8081"  # Production backend port
    env_file:
      - .env
    environment:
      - FLASK_ENV=production
      - FLASK_HOST=0.0.0.0  # Bind to all interfaces in Docker
      - DATABASE_URL=mysql+pymysql://${MYSQL_USER:-scheduling_user}:${MYSQL_PASSWORD:-scheduling_password}@mysql:3306/${MYSQL_DATABASE:-scheduling_system}?charset=utf8mb4
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - SECRET_KEY=${SECRET_KEY:-change-me-in-production}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-change-me-in-production}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/service-account-creds.json
      - CORS_ALLOWED_ORIGINS=http://82.165.209.92:8080,http://localhost:8080,http://localhost:5173,http://localhost:5174,http://127.0.0.1:8080,http://127.0.0.1:5173,http://127.0.0.1:5174
      - PYTHONPATH=/app/backend:/app
    command: >
      sh -c "alembic upgrade head && gunicorn --bind 0.0.0.0:8081 --workers=4 --threads=4 --timeout=120 --access-logfile - --error-logfile - --log-level info wsgi:application"
    volumes:
      - ./service-account-creds.json:/app/service-account-creds.json:ro
      - ./backend:/app/backend
      - ./logs:/app/logs
      - ./instance:/app/instance
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - scheduling-network
    restart: unless-stopped
    init: true
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8081/api/v1/health"]
      interval: 30s
      timeout: 10s
      start_period: 40s
      retries: 3

  # Celery Worker - Async task processing
  celery-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: scheduling-celery-worker
    command: sh -c "celery -A celery_worker.celery worker --loglevel=info --concurrency=4"
    env_file:
      - .env
    environment:
      - FLASK_ENV=production
      - DATABASE_URL=mysql+pymysql://${MYSQL_USER:-scheduling_user}:${MYSQL_PASSWORD:-scheduling_password}@mysql:3306/${MYSQL_DATABASE:-scheduling_system}?charset=utf8mb4
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - GOOGLE_APPLICATION_CREDENTIALS=/app/service-account-creds.json
      - PYTHONPATH=/app/backend:/app
    volumes:
      - ./service-account-creds.json:/app/service-account-creds.json:ro
      - ./backend:/app/backend
      - ./logs:/app/logs
      - ./instance:/app/instance
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      backend:
        condition: service_started
    networks:
      - scheduling-network
    restart: unless-stopped
    init: true

  # Celery Beat - Periodic task scheduler (optional)
  celery-beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: scheduling-celery-beat
    command: sh -c "celery -A celery_worker.celery beat --loglevel=info"
    env_file:
      - .env
    environment:
      - FLASK_ENV=production
      - DATABASE_URL=mysql+pymysql://${MYSQL_USER:-scheduling_user}:${MYSQL_PASSWORD:-scheduling_password}@mysql:3306/${MYSQL_DATABASE:-scheduling_system}?charset=utf8mb4
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - PYTHONPATH=/app/backend:/app
    volumes:
      - ./service-account-creds.json:/app/service-account-creds.json:ro
      - ./backend:/app/backend
      - ./logs:/app/logs
      - ./instance:/app/instance
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      backend:
        condition: service_started
    networks:
      - scheduling-network
    restart: unless-stopped
    init: true

  # AI Scheduling Service (Optional - comment out if not needed)
  # ai-service:
  #   build:
  #     context: ./ai_service
  #     dockerfile: Dockerfile
  #   container_name: scheduling-ai-service
  #   ports:
  #     - "5001:5001"
  #   environment:
  #     - PORT=5001
  #     - FLASK_ENV=production
  #   networks:
  #     - scheduling-network
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:5001/health')"]
  #     interval: 30s
  #     timeout: 10s
  #     start_period: 20s
  #     retries: 3

  # Frontend React Application
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - VITE_API_BASE_URL=/api/v1
    container_name: scheduling-frontend
    ports:
      - "8080:80"  # Production frontend port
    depends_on:
      - backend
    networks:
      - scheduling-network
    restart: unless-stopped

volumes:
  redis_data:
    driver: local
  mysql_data:
    driver: local

networks:
  scheduling-network:
    driver: bridge


